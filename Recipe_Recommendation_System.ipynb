{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "rAhsp3FeCtJq",
        "outputId": "44aad9b1-cb89-4fce-c3da-68c4b3ecb857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py (from anvil-uplink)\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45228 sha256=846feb7f42e2b06ad448fd5a1684be6525ca9dc156b5461e52fb0750f4958dac\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "446ac63f8aae4eaa910e1190e56f23dc",
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o160GwgDKAig",
        "outputId": "ec8ab825-1e63-483e-936c-32e0d20f1d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import drive\n",
        "import anvil.server\n",
        "anvil.server.connect(\"server_DB5KVIBTZTYYIEB6OPI2DBCZ-SNOWINEDJ3Y74TI4\")\n",
        "#from flask import Flask, render_template, request, jsonify\n",
        "\n",
        "#app = Flask(__name__)   ###\n",
        "\n",
        "# 讀主recipe & 資料前處理\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(r'/content/drive/MyDrive/Recipe Recommendation/all_recipe.csv')\n",
        "recipe = data['title'].astype(str) + ' ' + data['ingredients'].astype(str) + ' ' + data['instructions'].astype(str)\n",
        "recipe = [re.sub(r'\\b\\w*ADVERTISEMENT\\w*\\b', '', sentence) for sentence in recipe]\n",
        "recipe = [''.join(words) for words in recipe]\n",
        "recipe = pd.Series(recipe)\n",
        "# 讀取之前存好的子recipe\n",
        "recipe_indian = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_indian.csv')\n",
        "recipe_mexican = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_mexican.csv')\n",
        "recipe_french = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_french.csv')\n",
        "recipe_italian = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_italian.csv')\n",
        "recipe_japanese = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_japanese.csv')\n",
        "recipe_korean = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_korean.csv')\n",
        "recipe_spanish = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_spanish.csv')\n",
        "recipe_thai = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_thai.csv')\n",
        "recipe_american = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_american.csv')\n",
        "recipe_chinese = pd.read_csv('/content/drive/MyDrive/Recipe Recommendation/recipe_chinese.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 讀取事先訓練好的model\n",
        "tfidf_indian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_ind.pkl')\n",
        "vectorizer_indian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_ind.pkl')\n",
        "recipe_ind = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ind.pkl')\n",
        "recipe_IND = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_IND.pkl')\n",
        "\n",
        "tfidf_mexican = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_mex.pkl')\n",
        "vectorizer_mexican = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_mex.pkl')\n",
        "recipe_mex = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_mex.pkl')\n",
        "recipe_MEX = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_MEX.pkl')\n",
        "\n",
        "tfidf_french = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_fre.pkl')\n",
        "vectorizer_french = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_fre.pkl')\n",
        "recipe_fre = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_fre.pkl')\n",
        "recipe_FRE = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_FRE.pkl')\n",
        "\n",
        "tfidf_italian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_ita.pkl')\n",
        "vectorizer_italian = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_ita.pkl')\n",
        "recipe_ita = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ita.pkl')\n",
        "recipe_ITA = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ITA.pkl')\n",
        "\n",
        "tfidf_japanese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_jap.pkl')\n",
        "vectorizer_japanese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_jap.pkl')\n",
        "recipe_jap = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_jap.pkl')\n",
        "recipe_JAP = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_JAP.pkl')\n",
        "\n",
        "tfidf_korean = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_kor.pkl')\n",
        "vectorizer_korean = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_kor.pkl')\n",
        "recipe_kor = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_kor.pkl')\n",
        "recipe_KOR = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_KOR.pkl')\n",
        "\n",
        "tfidf_spanish = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_spa.pkl')\n",
        "vectorizer_spanish = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_spa.pkl')\n",
        "recipe_spa = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_spa.pkl')\n",
        "recipe_SPA = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_SPA.pkl')\n",
        "\n",
        "tfidf_thai = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_tha.pkl')\n",
        "vectorizer_thai = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_tha.pkl')\n",
        "recipe_tha = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_tha.pkl')\n",
        "recipe_THA = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_THA.pkl')\n",
        "\n",
        "tfidf_american = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_ame.pkl')\n",
        "vectorizer_american = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_ame.pkl')\n",
        "recipe_ame = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ame.pkl')\n",
        "recipe_AME = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_AME.pkl')\n",
        "\n",
        "tfidf_chinese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_chi.pkl')\n",
        "vectorizer_chinese = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_chi.pkl')\n",
        "recipe_chi = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_chi.pkl')\n",
        "recipe_CHI = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_CHI.pkl')\n",
        "\n",
        "tfidf = joblib.load('/content/drive/MyDrive/Recipe Recommendation/tfidf_all.pkl')\n",
        "vectorizer = joblib.load('/content/drive/MyDrive/Recipe Recommendation/vectorizer_all.pkl')\n",
        "recipe_all = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_all.pkl')\n",
        "recipe_ALL = joblib.load('/content/drive/MyDrive/Recipe Recommendation/recipe_ALL.pkl')\n",
        "\n",
        "indian_cuisine = ['Indian']\n",
        "mexican_cuisine = ['Mexican']\n",
        "french_cuisine = ['French']\n",
        "italian_cuisine = ['Italian']\n",
        "japanese_cuisine = ['Japanese']\n",
        "korean_cuisine = ['Korean']\n",
        "spanish_cuisine = ['Spanish']\n",
        "thai_cuisine = ['Thai']\n",
        "american_cuisine = ['American']\n",
        "chinese_cuisine = ['Chinese']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 創建一個dictionary方便核對question\n",
        "cuisines = {\n",
        "    \"indian_cuisine\": {\n",
        "        \"list\": indian_cuisine,\n",
        "        \"tfidf\": tfidf_indian,\n",
        "        \"vect\": vectorizer_indian,\n",
        "        \"transform\": recipe_ind,\n",
        "        \"transform1\": recipe_IND,\n",
        "        \"dataset\": recipe_indian\n",
        "    },\n",
        "    \"mexican_cuisine\": {\n",
        "        \"list\": mexican_cuisine,\n",
        "        \"tfidf\": tfidf_mexican,\n",
        "        \"vect\": vectorizer_mexican,\n",
        "        \"transform\": recipe_mex,\n",
        "        \"transform1\": recipe_MEX,\n",
        "        \"dataset\": recipe_mexican\n",
        "    },\n",
        "    \"french_cuisine\": {\n",
        "        \"list\": french_cuisine,\n",
        "        \"tfidf\": tfidf_french,\n",
        "        \"vect\": vectorizer_french,\n",
        "        \"transform\": recipe_fre,\n",
        "        \"transform1\": recipe_FRE,\n",
        "        \"dataset\": recipe_french\n",
        "    },\n",
        "    \"italian_cuisine\": {\n",
        "        \"list\": italian_cuisine,\n",
        "        \"tfidf\": tfidf_italian,\n",
        "        \"vect\": vectorizer_italian,\n",
        "        \"transform\": recipe_ita,\n",
        "        \"transform1\": recipe_ITA,\n",
        "        \"dataset\": recipe_italian\n",
        "    },\n",
        "    \"japanese_cuisine\": {\n",
        "        \"list\": japanese_cuisine,\n",
        "        \"tfidf\": tfidf_japanese,\n",
        "        \"vect\": vectorizer_japanese,\n",
        "        \"transform\": recipe_jap,\n",
        "        \"transform1\": recipe_JAP,\n",
        "        \"dataset\": recipe_japanese\n",
        "    },\n",
        "    \"korean_cuisine\": {\n",
        "        \"list\": korean_cuisine,\n",
        "        \"tfidf\": tfidf_korean,\n",
        "        \"vect\": vectorizer_korean,\n",
        "        \"transform\": recipe_kor,\n",
        "        \"transform1\": recipe_KOR,\n",
        "        \"dataset\": recipe_korean\n",
        "    },\n",
        "    \"spanish_cuisine\": {\n",
        "        \"list\": spanish_cuisine,\n",
        "        \"tfidf\": tfidf_spanish,\n",
        "        \"vect\": vectorizer_spanish,\n",
        "        \"transform\": recipe_spa,\n",
        "        \"transform1\": recipe_SPA,\n",
        "        \"dataset\": recipe_spanish\n",
        "    },\n",
        "    \"thai_cuisine\": {\n",
        "        \"list\": thai_cuisine,\n",
        "        \"tfidf\": tfidf_thai,\n",
        "        \"vect\": vectorizer_thai,\n",
        "        \"transform\": recipe_tha,\n",
        "        \"transform1\": recipe_THA,\n",
        "        \"dataset\": recipe_thai\n",
        "    },\n",
        "    \"american_cuisine\": {\n",
        "        \"list\": american_cuisine,\n",
        "        \"tfidf\": tfidf_american,\n",
        "        \"vect\": vectorizer_american,\n",
        "        \"transform\": recipe_ame,\n",
        "        \"transform1\": recipe_AME,\n",
        "        \"dataset\": recipe_american\n",
        "    },\n",
        "    \"chinese_cuisine\": {\n",
        "        \"list\": chinese_cuisine,\n",
        "        \"tfidf\": tfidf_chinese,\n",
        "        \"vect\": vectorizer_chinese,\n",
        "        \"transform\": recipe_chi,\n",
        "        \"transform1\": recipe_CHI,\n",
        "        \"dataset\": recipe_chinese\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "#@app.route('/')\n",
        "#def index():\n",
        "    #return render_template('index.html')\n",
        "\n",
        "#@app.route('/get_recommendations', methods=['POST'])\n",
        "#def get_recommendations():\n",
        "    #question = request.form['question']\n",
        "    #recommendations = get_recipe_recommendations(question)\n",
        "    #return jsonify({'recommendations': recommendations})\n",
        "\n",
        "@anvil.server.callable\n",
        "\n",
        "### 輸出dictionary\n",
        "\n",
        "def get_recipe_recommendations(question):\n",
        "    question_lower = question.lower()\n",
        "    recommendations = {\"title\": [], \"ingredients\": [], \"instructions\": []}  # 創建一個字典來存儲當前類型的推薦結果\n",
        "    for typ, cuisine in cuisines.items():\n",
        "        for key_word in cuisine[\"list\"]:\n",
        "            if key_word.lower() in question_lower:\n",
        "                X = cuisine[\"tfidf\"].transform([question])\n",
        "                Y = cuisine[\"vect\"].transform([question])\n",
        "                cosine_sim = np.ravel(cosine_similarity(X, cuisine[\"transform\"]))\n",
        "                recipe_intersections = cuisine[\"transform1\"].multiply(Y).sum(axis=1)\n",
        "                recipe_unions = cuisine[\"transform1\"].sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "                jaccard_similarity = recipe_intersections / recipe_unions\n",
        "                jaccard_sim = np.ravel(jaccard_similarity)\n",
        "                sim = cosine_sim + jaccard_sim\n",
        "                top_indices = np.argsort(-sim)[:3]\n",
        "                for index in top_indices:\n",
        "                    recipe_info = re.split('\\[|\\]', cuisine[\"dataset\"]['0'][index])\n",
        "                    recommendations[\"title\"].append(recipe_info[0])  # 將推薦結果添加到當前類型的字典中\n",
        "                    recommendations[\"ingredients\"].append(recipe_info[1])\n",
        "                    recommendations[\"instructions\"].append(recipe_info[2])\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "        break\n",
        "    else:\n",
        "        recommendations = {\"title\": [], \"ingredients\": [], \"instructions\": []}  # 創建一個字典來存儲所有的推薦結果\n",
        "        X = tfidf.transform([question])\n",
        "        Y = vectorizer.transform([question])\n",
        "        cosine_sim = np.ravel(cosine_similarity(X, recipe_all))\n",
        "        recipe_intersections = recipe_ALL.multiply(Y).sum(axis=1)\n",
        "        recipe_unions = recipe_ALL.sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "        jaccard_similarity = recipe_intersections / recipe_unions\n",
        "        jaccard_sim = np.ravel(jaccard_similarity)\n",
        "        sim = cosine_sim + jaccard_sim\n",
        "        top_indices = np.argsort(-sim)[:3]\n",
        "        for index in top_indices:\n",
        "            recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "            recommendations[\"title\"].append(recipe_info[0])  # 將推薦結果添加到所有推薦結果字典中\n",
        "            recommendations[\"ingredients\"].append(recipe_info[1])\n",
        "            recommendations[\"instructions\"].append(recipe_info[2])\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #from pyngrok import ngrok\n",
        "    # 啟動 ngrok 並公開 Flask 應用程序\n",
        "    #public_url = ngrok.connect(port=5000)\n",
        "    #print(' * Tunnel URL:', public_url)\n",
        "    # 啟動 Flask 應用程序\n",
        "    #app.run(debug=True)\n",
        "\n",
        "anvil.server.wait_forever()\n",
        "# 分析使用者的輸入並比對 (主要的模型輸出code)\n",
        "#while True:\n",
        "    #question = input(\"What is in your mind?\\n\")\n",
        "    #get_recipe_recommendations(question)\n",
        "    # 在這裡加入任何您想要的停止條件，比如使用者輸入特定指令以終止程式\n",
        "    #if input(\"Continue? (yes/no): \").lower() != \"yes\":\n",
        "        #break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chvrk9UHmYci"
      },
      "outputs": [],
      "source": [
        "### 輸出文字\n",
        "\n",
        "#def get_recipe_recommendations(question):\n",
        "    #recommendations = \"\"\n",
        "    #question_lower = question.lower()\n",
        "    #for typ, cuisine in cuisines.items():\n",
        "        #for key_word in cuisine[\"list\"]:\n",
        "            #if key_word.lower() in question_lower:\n",
        "                #X = cuisine[\"tfidf\"].transform([question])\n",
        "                #Y = cuisine[\"vect\"].transform([question])\n",
        "                #cosine_sim = np.ravel(cosine_similarity(X, cuisine[\"transform\"]))\n",
        "                #recipe_intersections = cuisine[\"transform1\"].multiply(Y).sum(axis=1)\n",
        "                #recipe_unions = cuisine[\"transform1\"].sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "                #jaccard_similarity = recipe_intersections / recipe_unions\n",
        "                #jaccard_sim = np.ravel(jaccard_similarity)\n",
        "                #sim = cosine_sim + jaccard_sim\n",
        "                #top_indices = np.argsort(-sim)[:3]\n",
        "                #for i, index in enumerate(top_indices, 1):\n",
        "                    #recipe_info = re.split('\\[|\\]', cuisine[\"dataset\"][index])\n",
        "                    #recommendations += f\"Recommendation {i}:\\n\"\n",
        "                    #recommendations += f\"{recipe_info[0]}\\n\"  # Title\n",
        "                    #recommendations += f\"*Ingredients:\\n{recipe_info[1]}\\n\"\n",
        "                    #recommendations += f\"*Instructions:\\n{recipe_info[2]}\\n\\n\"\n",
        "                #return recommendations\n",
        "    #else:\n",
        "        #X = tfidf.transform([question])\n",
        "        #Y = vectorizer.transform([question])\n",
        "        #cosine_sim = np.ravel(cosine_similarity(X, recipe_all))\n",
        "        #recipe_intersections = recipe_ALL.multiply(Y).sum(axis=1)\n",
        "        #recipe_unions = recipe_ALL.sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "        #jaccard_similarity = recipe_intersections / recipe_unions\n",
        "        #jaccard_sim = np.ravel(jaccard_similarity)\n",
        "        #sim = cosine_sim + jaccard_sim\n",
        "        #top_indices = np.argsort(-sim)[:3]\n",
        "        #for i, index in enumerate(top_indices, 1):\n",
        "            #recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "            #recommendations += f\"Recommendation {i}:\\n\"\n",
        "            #recommendations += f\"{recipe_info[0]}\\n\"  # Title\n",
        "            #recommendations += f\"*Ingredients:\\n{recipe_info[1]}\\n\"\n",
        "            #recommendations += f\"*Instructions:\\n{recipe_info[2]}\\n\\n\"\n",
        "        #return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqhP2F3Fkd76"
      },
      "outputs": [],
      "source": [
        "### 輸出dictionary\n",
        "\n",
        "#def get_recipe_recommendations(question):\n",
        "    #question_lower = question.lower()\n",
        "    #recommendations = {\"title\": [], \"ingredients\": [], \"instructions\": []}  # 創建一個字典來存儲當前類型的推薦結果\n",
        "    #for typ, cuisine in cuisines.items():\n",
        "        #for key_word in cuisine[\"list\"]:\n",
        "            #if key_word.lower() in question_lower:\n",
        "                #X = cuisine[\"tfidf\"].transform([question])\n",
        "                #Y = cuisine[\"vect\"].transform([question])\n",
        "                #cosine_sim = np.ravel(cosine_similarity(X, cuisine[\"transform\"]))\n",
        "                #recipe_intersections = cuisine[\"transform1\"].multiply(Y).sum(axis=1)\n",
        "                #recipe_unions = cuisine[\"transform1\"].sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "                #jaccard_similarity = recipe_intersections / recipe_unions\n",
        "                #jaccard_sim = np.ravel(jaccard_similarity)\n",
        "                #sim = cosine_sim + jaccard_sim\n",
        "                #top_indices = np.argsort(-sim)[:3]\n",
        "                #for index in top_indices:\n",
        "                    #recipe_info = re.split('\\[|\\]', cuisine[\"dataset\"][index])\n",
        "                    #recommendations[\"title\"].append(recipe_info[0])  # 將推薦結果添加到當前類型的字典中\n",
        "                    #recommendations[\"ingredients\"].append(recipe_info[1])\n",
        "                    #recommendations[\"instructions\"].append(recipe_info[2])\n",
        "    #else:\n",
        "        #recommendations = {\"title\": [], \"ingredients\": [], \"instructions\": []}  # 創建一個字典來存儲所有的推薦結果\n",
        "        #X = tfidf.transform([question])\n",
        "        #Y = vectorizer.transform([question])\n",
        "        #cosine_sim = np.ravel(cosine_similarity(X, recipe_all))\n",
        "        #recipe_intersections = recipe_ALL.multiply(Y).sum(axis=1)\n",
        "        #recipe_unions = recipe_ALL.sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "        #jaccard_similarity = recipe_intersections / recipe_unions\n",
        "        #jaccard_sim = np.ravel(jaccard_similarity)\n",
        "        #sim = cosine_sim + jaccard_sim\n",
        "        #top_indices = np.argsort(-sim)[:3]\n",
        "        #for index in top_indices:\n",
        "            #recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "            #recommendations[\"title\"].append(recipe_info[0])  # 將推薦結果添加到所有推薦結果字典中\n",
        "            #recommendations[\"ingredients\"].append(recipe_info[1])\n",
        "            #recommendations[\"instructions\"].append(recipe_info[2])\n",
        "    #return recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHQur-QZY9c5"
      },
      "outputs": [],
      "source": [
        "#def get_recipe_recommendations(question):\n",
        "  #question_lower = question.lower()\n",
        "  ####Title = []\n",
        "  ####Ingredients = []\n",
        "  ####Instructions = []\n",
        "  #for typ, cuisine in cuisines.items():\n",
        "      #for key_word in cuisine[\"list\"]:\n",
        "          #if key_word.lower() in question_lower:\n",
        "              #X = cuisine[\"tfidf\"].transform([question])\n",
        "              #Y = cuisine[\"vect\"].transform([question])\n",
        "              #cosine_sim = np.ravel(cosine_similarity(X, cuisine[\"transform\"]))\n",
        "              #recipe_intersections = cuisine[\"transform1\"].multiply(Y).sum(axis=1)\n",
        "              #recipe_unions = cuisine[\"transform1\"].sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "              #jaccard_similarity = recipe_intersections / recipe_unions\n",
        "              #jaccard_sim = np.ravel(jaccard_similarity)\n",
        "              #sim = cosine_sim + jaccard_sim\n",
        "              #top_indices = np.argsort(-sim)[:3]\n",
        "              ####print(question)\n",
        "              ####print('---------------------------------------------------------------------------')\n",
        "              #for i, index in enumerate(top_indices, 1):\n",
        "                  #recipe_info = re.split('\\[|\\]', cuisine[\"dataset\"][index])\n",
        "                  ####print(f\"Recommendation {i} , The similarity is {sim[index]}:\")\n",
        "                  #print(f\"Recommendation {i}:\")\n",
        "                  ####print('*Title:')\n",
        "                  #print(recipe_info[0],'\\n')\n",
        "                  ####Title.append(recipe_info[0])\n",
        "                  #print('*Ingredients:')\n",
        "                  #print(recipe_info[1],'\\n')\n",
        "                  #####Ingredients.append(recipe_info[1])\n",
        "                  #print('*Instructions:')\n",
        "                  #print(recipe_info[2],'\\n')\n",
        "                  #####Instructions.append(recipe_info[2])\n",
        "                  #print('\\n')\n",
        "              #break\n",
        "      #else:\n",
        "          #continue\n",
        "      #break\n",
        "  #else:\n",
        "      #X = tfidf.transform([question])\n",
        "      #Y = vectorizer.transform([question])\n",
        "      #cosine_sim = np.ravel(cosine_similarity(X, recipe_all))\n",
        "      #recipe_intersections = recipe_ALL.multiply(Y).sum(axis=1)\n",
        "      #recipe_unions = recipe_ALL.sum(axis=1) + Y.sum(axis=1) - recipe_intersections\n",
        "      #jaccard_similarity = recipe_intersections / recipe_unions\n",
        "      #jaccard_sim = np.ravel(jaccard_similarity)\n",
        "      #sim = cosine_sim + jaccard_sim\n",
        "      #top_indices = np.argsort(-sim)[:3]\n",
        "      ####print(question)\n",
        "      ####print('---------------------------------------------------------------------------')\n",
        "      #for i, index in enumerate(top_indices, 1):\n",
        "          #recipe_info = re.split('\\[|\\]', recipe[index])\n",
        "          ####print(f\"Recommendation {i} , The similarity is {sim[index]}:\")\n",
        "          #print(f\"Recommendation {i}:\")\n",
        "          ####print('*Title:')\n",
        "          #print(recipe_info[0],'\\n')\n",
        "          ####Title.append(recipe_info[0])\n",
        "          #print('*Ingredients:')\n",
        "          #print(recipe_info[1],'\\n')\n",
        "          ####Ingredients.append(recipe_info[1])\n",
        "          #print('*Instructions:')\n",
        "          #print(recipe_info[2],'\\n')\n",
        "          ####Instructions.append(recipe_info[2])\n",
        "          #print('\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}